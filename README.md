# Automated Sign Language STEM Content Generation

## Overview
Automated Sign Language STEM Content Generation is an AI-based accessibility platform designed to enhance learning experience for deaf and mute students further aiding their STEM endeavours. The system converts complex STEM concepts into simplified explanations, visual representations, and sign language learning resources to improve understanding and inclusivity.

---

## Problem Addressed
Despite the rapid growth of digital education, STEM content remains largely inaccessible to deaf and mute learners. Most learning materials rely on spoken explanations or linguistically complex text, requiring skilled interpreters and manual content creation. This results in limited subject coverage, high costs, and reduced scalability in inclusive education.

---

## Proposed Solution
This project introduces an AI-powered web platform that automatically converts STEM content into structured sign language learning material. The system simplifies complex concepts, maps keywords to visual resources, and presents explanations using images, graphs, and a curated sign language video library developed as part of the project.

---

## Key Features
- AI-based concept detection and explanation generation
- Simplified STEM text for better comprehension
- Visual learning through images and graphs
- Integration with custom sign language video library
- Keyword-based navigation for related topics
- Interactive web-based interface
- Modular and scalable architecture

---

## Workflow
1. User enters a STEM query or uploads content
2. Backend processes input and detects concepts
3. System retrieves simplified explanation and visuals
4. Relevant sign language videos from the internal library are mapped
5. Output presented via interactive UI

---

## Tech Stack
### Frontend
- Next.js
- React
- Tailwind CSS

### Backend
- FastAPI
- Python

### Data & Storage
- JSON-based concept repository
- CSV sign language dataset
- Media asset library (images & sign videos)

### Core Technologies
- Automated text processing
- Concept mapping engine
- Sign language mapping module
- API-based frontend-backend communication

---

## Future Scope
- 3D animated sign language avatar
- Real-time sign recognition interaction
- OCR-based PDF and textbook processing
- Multi-language sign support
- LMS integration for institutions
- Cloud deployment for scalability

---

## Impact
This project aims to create an inclusive STEM learning ecosystem by reducing dependency on manual sign language content creation while improving accessibility, scalability, and affordability in deaf education.

---

## Team INNOVATRIX
- Harsh Jain – Team Lead & Product Strategist
- Bijli Rakesh – Data & Deployment Engineer
- Naman Jain – Full Stack Developer
- Swastik Ratha – Accessibility & Sign Language Research Lead
- Abhinav Karn – AI Developer
